

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>spsklearn.cluster &mdash; Spherical-Scikit-Learn 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=01f34227"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="spsklearn.mixture" href="../mixture/index.html" />
    <link rel="prev" title="spsklearn" href="../index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html">
            
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Main:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">spsklearn</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../index.html#submodules">Submodules</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#">spsklearn.cluster</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#classes">Classes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#functions">Functions</a></li>
<li class="toctree-l5"><a class="reference internal" href="#package-contents">Package Contents</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="../mixture/index.html">spsklearn.mixture</a></li>
<li class="toctree-l4"><a class="reference internal" href="../utils/index.html">spsklearn.utils</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Spherical-Scikit-Learn</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">API Reference</a></li>
          <li class="breadcrumb-item"><a href="../index.html">spsklearn</a></li>
      <li class="breadcrumb-item active">spsklearn.cluster</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/autoapi/spsklearn/cluster/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-spsklearn.cluster">
<span id="spsklearn-cluster"></span><h1>spsklearn.cluster<a class="headerlink" href="#module-spsklearn.cluster" title="Link to this heading"></a></h1>
<p>The <a class="reference internal" href="#module-spsklearn.cluster" title="spsklearn.cluster"><code class="xref py py-mod docutils literal notranslate"><span class="pre">spsklearn.cluster</span></code></a> module implements clustering algorithms.</p>
<section id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Link to this heading"></a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#spsklearn.cluster.SphericalKMeans" title="spsklearn.cluster.SphericalKMeans"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SphericalKMeans</span></code></a></p></td>
<td><p>Spherical K-Means clustering.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Link to this heading"></a></h2>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#spsklearn.cluster.spherical_k_means_plusplus" title="spsklearn.cluster.spherical_k_means_plusplus"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spherical_k_means_plusplus</span></code></a>(X, n_clusters, *[, ...])</p></td>
<td><p>Init n_clusters seeds according to spherical k-means++.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#spsklearn.cluster.spherical_k_means" title="spsklearn.cluster.spherical_k_means"><code class="xref py py-obj docutils literal notranslate"><span class="pre">spherical_k_means</span></code></a>(X, n_clusters, *[, sample_weight, ...])</p></td>
<td><p>Perform K-means clustering algorithm.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Link to this heading"></a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="spsklearn.cluster.spherical_k_means_plusplus">
<span class="sig-prename descclassname"><span class="pre">spsklearn.cluster.</span></span><span class="sig-name descname"><span class="pre">spherical_k_means_plusplus</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_local_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spsklearn.cluster.spherical_k_means_plusplus" title="Link to this definition"></a></dt>
<dd><p>Init n_clusters seeds according to spherical k-means++.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The data to pick seeds from.</p></li>
<li><p><strong>n_clusters</strong> (<em>int</em>) – The number of centroids to initialize.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The weights for each observation in <cite>X</cite>. If <cite>None</cite>, all observations
are assigned equal weight. <cite>sample_weight</cite> is ignored if <cite>init</cite>
is a callable or a user provided array.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em> or </em><em>RandomState instance</em><em>, </em><em>default=None</em>) – Determines random number generation for centroid initialization. Pass
an int for reproducible output across multiple function calls.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>n_local_trials</strong> (<em>int</em><em>, </em><em>default=None</em>) – The number of seeding trials for each center (except the first),
of which the one reducing inertia the most is greedily chosen.
Set to None to make the number of trials depend logarithmically
on the number of seeds (2+log(k)) which is the recommended setting.
Setting to 1 disables the greedy cluster selection and recovers the
vanilla k-means++ algorithm which was empirically shown to work less
well than its greedy variant.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>centers</strong> (<em>ndarray of shape (n_clusters, n_features)</em>) – The initial centers for k-means.</p></li>
<li><p><strong>indices</strong> (<em>ndarray of shape (n_clusters,)</em>) – The index location of the chosen centers in the data array X. For a
given index and center, X[index] = center.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Notes</p>
<p>Selects initial cluster centers for spherical k-mean clustering in a smart way
to speed up convergence. see: Arthur, D. and Vassilvitskii, S.
“k-means++: the advantages of careful seeding”. ACM-SIAM symposium
on Discrete algorithms. 2007</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="spsklearn.cluster.spherical_k_means">
<span class="sig-prename descclassname"><span class="pre">spsklearn.cluster.</span></span><span class="sig-name descname"><span class="pre">spherical_k_means</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'spherical-k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lloyd'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_n_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spsklearn.cluster.spherical_k_means" title="Link to this definition"></a></dt>
<dd><p>Perform K-means clustering algorithm.</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – The observations to cluster. It must be noted that the data
will be converted to C ordering, which will cause a memory copy
if the given data is not C-contiguous.</p></li>
<li><p><strong>n_clusters</strong> (<em>int</em>) – The number of clusters to form as well as the number of
centroids to generate.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The weights for each observation in <cite>X</cite>. If <cite>None</cite>, all observations
are assigned equal weight. <cite>sample_weight</cite> is not used during
initialization if <cite>init</cite> is a callable or a user provided array.</p></li>
<li><p><strong>init</strong> (<em>{'spherical-k-means++'</em><em>, </em><em>'random'}</em><em>, </em><em>callable</em><em> or </em><em>array-like</em><em> of </em><em>shape</em><em>             (</em><em>n_clusters</em><em>, </em><em>n_features</em><em>)</em><em>, </em><em>default='spherical-k-means++'</em>) – <p>Method for initialization:</p>
<ul>
<li><p><cite>’spherical-k-means++’</cite> : selects initial cluster centers for k-mean
clustering in a smart way to speed up convergence. See section
Notes in k_init for more details.</p></li>
<li><p><cite>’random’</cite>: choose <cite>n_clusters</cite> observations (rows) at random from data
for the initial centroids.</p></li>
<li><p>If an array is passed, it should be of shape <cite>(n_clusters, n_features)</cite>
and gives the initial centers.</p></li>
<li><p>If a callable is passed, it should take arguments <cite>X</cite>, <cite>n_clusters</cite> and a
random state and return an initialization.</p></li>
</ul>
</p></li>
<li><p><strong>n_init</strong> (<em>'auto'</em><em> or </em><em>int</em><em>, </em><em>default=&quot;auto&quot;</em>) – <p>Number of time the k-means algorithm will be run with different
centroid seeds. The final results will be the best output of
n_init consecutive runs in terms of inertia.</p>
<p>When <cite>n_init=’auto’</cite>, the number of runs depends on the value of init:
10 if using <cite>init=’random’</cite> or <cite>init</cite> is a callable;
1 if using <cite>init=’spherical-k-means++’</cite> or <cite>init</cite> is an array-like.</p>
<div class="versionadded">
<p><span class="versionmodified added">Added in version 1.2: </span>Added ‘auto’ option for <cite>n_init</cite>.</p>
</div>
<div class="versionchanged">
<p><span class="versionmodified changed">Changed in version 1.4: </span>Default value for <cite>n_init</cite> changed to <cite>‘auto’</cite>.</p>
</div>
</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>default=300</em>) – Maximum number of iterations of the k-means algorithm to run.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Verbosity mode.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=1e-4</em>) – Relative tolerance with regards to Frobenius norm of the difference
in the cluster centers of two consecutive iterations to declare
convergence.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation for centroid initialization. Use
an int to make the randomness deterministic.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>copy_x</strong> (<em>bool</em><em>, </em><em>default=True</em>) – When pre-computing distances it is more numerically accurate to center
the data first. If <cite>copy_x</cite> is True (default), then the original data is
not modified. If False, the original data is modified, and put back
before the function returns, but small numerical differences may be
introduced by subtracting and then adding the data mean. Note that if
the original data is not C-contiguous, a copy will be made even if
<cite>copy_x</cite> is False. If the original data is sparse, but not in CSR format,
a copy will be made even if <cite>copy_x</cite> is False.</p></li>
<li><p><strong>algorithm</strong> (<em>{&quot;lloyd&quot;}</em><em>, </em><em>default=&quot;lloyd&quot;</em>) – K-means algorithm to use. The classical EM-style algorithm is <cite>“lloyd”</cite>.
The <cite>“elkan”</cite> variation can be more efficient on some datasets with
well-defined clusters, by using the triangle inequality. However it’s
more memory intensive due to the allocation of an extra array of shape
<cite>(n_samples, n_clusters)</cite>.</p></li>
<li><p><strong>return_n_iter</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Whether or not to return the number of iterations.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>centroid</strong> (<em>ndarray of shape (n_clusters, n_features)</em>) – Centroids found at the last iteration of k-means.</p></li>
<li><p><strong>label</strong> (<em>ndarray of shape (n_samples,)</em>) – The <cite>label[i]</cite> is the code or index of the centroid the
i’th observation is closest to.</p></li>
<li><p><strong>inertia</strong> (<em>float</em>) – The final value of the inertia criterion (sum of squared distances to
the closest centroid for all observations in the training set).</p></li>
<li><p><strong>best_n_iter</strong> (<em>int</em>) – Number of iterations corresponding to the best results.
Returned only if <cite>return_n_iter</cite> is set to True.</p></li>
</ul>
</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.cluster</span><span class="w"> </span><span class="kn">import</span> <span class="n">k_means</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">centroid</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">inertia</span> <span class="o">=</span> <span class="n">k_means</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">centroid</span>
<span class="go">array([[10.,  2.],</span>
<span class="go">       [ 1.,  2.]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">label</span>
<span class="go">array([1, 1, 1, 0, 0, 0], dtype=int32)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inertia</span>
<span class="go">16.0</span>
</pre></div>
</div>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">spsklearn.cluster.</span></span><span class="sig-name descname"><span class="pre">SphericalKMeans</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_clusters</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">8</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'spherical-k-means++'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_init</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'auto'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">300</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">random_state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">copy_x</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">algorithm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'lloyd'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.cluster._kmeans._BaseKMeans</span></code></p>
digraph inheritance076c7e5468 {
bgcolor=transparent;
rankdir=LR;
size=&quot;8.0, 12.0&quot;;
  &quot;SphericalKMeans&quot; [fillcolor=white,fontname=&quot;Vera Sans, DejaVu Sans, Liberation Sans, Arial, Helvetica, sans&quot;,fontsize=10,height=0.25,shape=box,style=&quot;setlinewidth(0.5),filled&quot;,tooltip=&quot;Spherical K-Means clustering.&quot;];
}
<p>Spherical K-Means clustering.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_clusters</strong> (<em>int</em><em>, </em><em>default=8</em>) – The number of clusters to form as well as the number of
centroids to generate.</p></li>
<li><p><strong>init</strong> (<em>{'spherical-k-means++'</em><em>, </em><em>'random'}</em><em>, </em><em>callable</em><em> or </em><em>array-like</em><em> of </em><em>shape</em><em>             (</em><em>n_clusters</em><em>, </em><em>n_features</em><em>)</em><em>, </em><em>default='spherical-k-means++'</em>) – <p>Method for initialization:</p>
<ul>
<li><p>’spherical-k-means++’ : selects initial cluster centroids using sampling             based on an empirical probability distribution of the points’             contribution to the overall inertia. This technique speeds up             convergence. The algorithm implemented is “greedy spherical-k-means++”. It             differs from the vanilla spherical-k-means++ by making several trials at             each sampling step and choosing the best centroid among them.</p></li>
<li><p>’random’: choose <cite>n_clusters</cite> observations (rows) at random from         data for the initial centroids.</p></li>
<li><p>If an array is passed, it should be of shape (n_clusters, n_features)        and gives the initial centers.</p></li>
<li><p>If a callable is passed, it should take arguments X, n_clusters and a        random state and return an initialization.</p></li>
</ul>
<p>For an example of how to use the different <cite>init</cite> strategy, see the example
entitled <span class="xref std std-ref">sphx_glr_auto_examples_cluster_plot_kmeans_digits.py</span>.</p>
</p></li>
<li><p><strong>n_init</strong> (<em>'auto'</em><em> or </em><em>int</em><em>, </em><em>default='auto'</em>) – <p>Number of times the k-means algorithm is run with different centroid
seeds. The final results is the best output of <cite>n_init</cite> consecutive runs
in terms of inertia. Several runs are recommended for sparse
high-dimensional problems (see <span class="xref std std-ref">kmeans_sparse_high_dim</span>).</p>
<p>When <cite>n_init=’auto’</cite>, the number of runs depends on the value of init:
10 if using <cite>init=’random’</cite> or <cite>init</cite> is a callable;
1 if using <cite>init=’spherical-k-means++’</cite> or <cite>init</cite> is an array-like.</p>
</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>default=300</em>) – Maximum number of iterations of the k-means algorithm for a
single run.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=1e-4</em>) – Relative tolerance with regards to Frobenius norm of the difference
in the cluster centers of two consecutive iterations to declare
convergence.</p></li>
<li><p><strong>verbose</strong> (<em>int</em><em>, </em><em>default=0</em>) – Verbosity mode.</p></li>
<li><p><strong>random_state</strong> (<em>int</em><em>, </em><em>RandomState instance</em><em> or </em><em>None</em><em>, </em><em>default=None</em>) – Determines random number generation for centroid initialization. Use
an int to make the randomness deterministic.
See <span class="xref std std-term">Glossary</span>.</p></li>
<li><p><strong>copy_x</strong> (<em>bool</em><em>, </em><em>default=True</em>) – When pre-computing distances it is more numerically accurate to center
the data first. If copy_x is True (default), then the original data is
not modified. If False, the original data is modified, and put back
before the function returns, but small numerical differences may be
introduced by subtracting and then adding the data mean. Note that if
the original data is not C-contiguous, a copy will be made even if
copy_x is False. If the original data is sparse, but not in CSR format,
a copy will be made even if copy_x is False.</p></li>
<li><p><strong>algorithm</strong> (<em>{&quot;lloyd&quot;}</em><em>, </em><em>default=&quot;lloyd&quot;</em>) – spherical K-means algorithm to use. The classical EM-style algorithm is <cite>“lloyd”</cite>.
The <cite>“elkan”</cite> variation can be more efficient on some datasets with
well-defined clusters, by using the triangle inequality. However it’s
more memory intensive due to the allocation of an extra array of shape
<cite>(n_samples, n_clusters)</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.cluster_centers_">
<span class="sig-name descname"><span class="pre">cluster_centers_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.cluster_centers_" title="Link to this definition"></a></dt>
<dd><p>Coordinates of cluster centers. If the algorithm stops before fully
converging (see <code class="docutils literal notranslate"><span class="pre">tol</span></code> and <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>), these will not be
consistent with <code class="docutils literal notranslate"><span class="pre">labels_</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_clusters, n_features)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.labels_">
<span class="sig-name descname"><span class="pre">labels_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.labels_" title="Link to this definition"></a></dt>
<dd><p>Labels of each point</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (n_samples,)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.inertia_">
<span class="sig-name descname"><span class="pre">inertia_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.inertia_" title="Link to this definition"></a></dt>
<dd><p>Sum of squared distances of samples to their closest cluster center,
weighted by the sample weights if provided.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.n_iter_">
<span class="sig-name descname"><span class="pre">n_iter_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.n_iter_" title="Link to this definition"></a></dt>
<dd><p>Number of iterations run.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.n_features_in_">
<span class="sig-name descname"><span class="pre">n_features_in_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.n_features_in_" title="Link to this definition"></a></dt>
<dd><p>Number of features seen during <span class="xref std std-term">fit</span>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.feature_names_in_">
<span class="sig-name descname"><span class="pre">feature_names_in_</span></span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.feature_names_in_" title="Link to this definition"></a></dt>
<dd><p>Names of features seen during <span class="xref std std-term">fit</span>. Defined only when <cite>X</cite>
has feature names that are all strings.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>ndarray of shape (<cite>n_features_in_</cite>,)</p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Notes</p>
<p>The spherical k-means problem is solved using either Lloyd’s or Elkan’s algorithm.</p>
<p>The average complexity is given by O(k n T), where n is the number of
samples and T is the number of iteration.</p>
<p>The worst case complexity is given by O(n^(k+2/p)) with
n = n_samples, p = n_features.
Refer to <a href="#id1"><span class="problematic" id="id2">:doi:`&quot;How slow is the k-means method?&quot; D. Arthur and S. Vassilvitskii -
SoCG2006.&lt;10.1145/1137856.1137880&gt;`</span></a> for more details.</p>
<p>In practice, the k-means algorithm is very fast (one of the fastest
clustering algorithms available), but it falls in local minima. That’s why
it can be useful to restart it several times.</p>
<p>If the algorithm stops before fully converging (because of <code class="docutils literal notranslate"><span class="pre">tol</span></code> or
<code class="docutils literal notranslate"><span class="pre">max_iter</span></code>), <code class="docutils literal notranslate"><span class="pre">labels_</span></code> and <code class="docutils literal notranslate"><span class="pre">cluster_centers_</span></code> will not be consistent,
i.e. the <code class="docutils literal notranslate"><span class="pre">cluster_centers_</span></code> will not be the means of the points in each
cluster. Also, the estimator will reassign <code class="docutils literal notranslate"><span class="pre">labels_</span></code> after the last
iteration to make <code class="docutils literal notranslate"><span class="pre">labels_</span></code> consistent with <code class="docutils literal notranslate"><span class="pre">predict</span></code> on the training
set.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.copy_x">
<span class="sig-name descname"><span class="pre">copy_x</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.copy_x" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.algorithm">
<span class="sig-name descname"><span class="pre">algorithm</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'lloyd'</span></em><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.algorithm" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="spsklearn.cluster.SphericalKMeans.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">X</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sample_weight</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#spsklearn.cluster.SphericalKMeans.fit" title="Link to this definition"></a></dt>
<dd><p>Compute spherical k-means clustering.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>, </em><em>n_features</em><em>)</em>) – Training instances to cluster. It must be noted that the data
will be converted to C ordering, which will cause a memory
copy if the given data is not C-contiguous.
If a sparse matrix is passed, a copy will be made if it’s not in
CSR format.</p></li>
<li><p><strong>y</strong> (<em>Ignored</em>) – Not used, present here for API consistency by convention.</p></li>
<li><p><strong>sample_weight</strong> (<em>array-like</em><em> of </em><em>shape</em><em> (</em><em>n_samples</em><em>,</em><em>)</em><em>, </em><em>default=None</em>) – The weights for each observation in X. If None, all observations
are assigned equal weight. <cite>sample_weight</cite> is not used during
initialization if <cite>init</cite> is a callable or a user provided array.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>self</strong> – Fitted estimator.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>object</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../index.html" class="btn btn-neutral float-left" title="spsklearn" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../mixture/index.html" class="btn btn-neutral float-right" title="spsklearn.mixture" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright Jiaqi Li.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>