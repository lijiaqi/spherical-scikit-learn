

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>spsklearn.cluster._spherical_k_means &mdash; Spherical-Scikit-Learn 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home" alt="Documentation Home"> Spherical-Scikit-Learn
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Main:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../autoapi/index.html">API Reference</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">Spherical-Scikit-Learn</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
          <li><a href="../cluster.html">spsklearn.cluster</a> &raquo;</li>
        
      <li>spsklearn.cluster._spherical_k_means</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for spsklearn.cluster._spherical_k_means</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Spherical K-means clustering.&quot;&quot;&quot;</span>

<span class="c1"># Authors: Jiaqi Li &lt;lijiaqi.academic@outlook.com&gt;</span>
<span class="c1"># License: BSD 3 clause</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">numbers</span> <span class="kn">import</span> <span class="n">Integral</span><span class="p">,</span> <span class="n">Real</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sp</span>


<span class="c1"># from sklearn.base import (</span>
<span class="c1">#     BaseEstimator,</span>
<span class="c1">#     ClassNamePrefixFeaturesOutMixin,</span>
<span class="c1">#     ClusterMixin,</span>
<span class="c1">#     TransformerMixin,</span>
<span class="c1">#     _fit_context,</span>
<span class="c1"># )</span>
<span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">_fit_context</span>
<span class="kn">from</span> <span class="nn">sklearn.exceptions</span> <span class="kn">import</span> <span class="n">ConvergenceWarning</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">_euclidean_distances</span><span class="p">,</span> <span class="n">euclidean_distances</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_distances</span><span class="p">,</span> <span class="n">cosine_similarity</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">check_array</span><span class="p">,</span> <span class="n">check_random_state</span>
<span class="kn">from</span> <span class="nn">sklearn.utils._openmp_helpers</span> <span class="kn">import</span> <span class="n">_openmp_effective_n_threads</span>
<span class="kn">from</span> <span class="nn">sklearn.utils._param_validation</span> <span class="kn">import</span> <span class="n">Interval</span><span class="p">,</span> <span class="n">StrOptions</span><span class="p">,</span> <span class="n">validate_params</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.extmath</span> <span class="kn">import</span> <span class="n">row_norms</span><span class="p">,</span> <span class="n">stable_cumsum</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">threadpool_info</span><span class="p">,</span> <span class="n">threadpool_limits</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.sparsefuncs</span> <span class="kn">import</span> <span class="n">mean_variance_axis</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.sparsefuncs_fast</span> <span class="kn">import</span> <span class="n">assign_rows_csr</span>
<span class="kn">from</span> <span class="nn">sklearn.utils.validation</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_sample_weight</span><span class="p">,</span>
    <span class="n">_is_arraylike_not_scalar</span><span class="p">,</span>
    <span class="n">check_is_fitted</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster._kmeans</span> <span class="kn">import</span> <span class="n">_BaseKMeans</span>

<span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">check_spherical_array</span>
<span class="kn">from</span> <span class="nn">._spherical_k_means_common</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CHUNK_SIZE</span><span class="p">,</span>
    <span class="n">_inertia_dense</span><span class="p">,</span>
    <span class="n">_inertia_sparse</span><span class="p">,</span>
    <span class="n">_is_same_clustering</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">._spherical_k_means_lloyd</span> <span class="kn">import</span> <span class="n">lloyd_iter_chunked_dense</span><span class="p">,</span> <span class="n">lloyd_iter_chunked_sparse</span>

<span class="c1"># from ._k_means_minibatch import _minibatch_update_dense, _minibatch_update_sparse</span>

<span class="c1">###############################################################################</span>
<span class="c1"># Initialization heuristic</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_clusters&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">)],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">],</span>
        <span class="s2">&quot;n_local_trials&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<div class="viewcode-block" id="spherical_k_means_plusplus"><a class="viewcode-back" href="../../../autoapi/spsklearn/cluster/index.html#spsklearn.cluster._spherical_k_means.spherical_k_means_plusplus">[docs]</a><span class="p">)</span>
<span class="k">def</span> <span class="nf">spherical_k_means_plusplus</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Init n_clusters seeds according to spherical k-means++.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to pick seeds from.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of centroids to initialize.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        The weights for each observation in `X`. If `None`, all observations</span>
<span class="sd">        are assigned equal weight. `sample_weight` is ignored if `init`</span>
<span class="sd">        is a callable or a user provided array.</span>

<span class="sd">    random_state : int or RandomState instance, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Pass</span>
<span class="sd">        an int for reproducible output across multiple function calls.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    n_local_trials : int, default=None</span>
<span class="sd">        The number of seeding trials for each center (except the first),</span>
<span class="sd">        of which the one reducing inertia the most is greedily chosen.</span>
<span class="sd">        Set to None to make the number of trials depend logarithmically</span>
<span class="sd">        on the number of seeds (2+log(k)) which is the recommended setting.</span>
<span class="sd">        Setting to 1 disables the greedy cluster selection and recovers the</span>
<span class="sd">        vanilla k-means++ algorithm which was empirically shown to work less</span>
<span class="sd">        well than its greedy variant.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers for k-means.</span>

<span class="sd">    indices : ndarray of shape (n_clusters,)</span>
<span class="sd">        The index location of the chosen centers in the data array X. For a</span>
<span class="sd">        given index and center, X[index] = center.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Selects initial cluster centers for spherical k-mean clustering in a smart way</span>
<span class="sd">    to speed up convergence. see: Arthur, D. and Vassilvitskii, S.</span>
<span class="sd">    &quot;k-means++: the advantages of careful seeding&quot;. ACM-SIAM symposium</span>
<span class="sd">    on Discrete algorithms. 2007</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Check data</span>
    <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">])</span>
    <span class="n">check_spherical_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">spherical_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">n_clusters</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_samples=</span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> should be &gt;= n_clusters=</span><span class="si">{</span><span class="n">n_clusters</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="n">random_state</span><span class="p">)</span>

    <span class="c1"># Call private spherical k-means++</span>
    <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">_spherical_k_means_plusplus</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">n_local_trials</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span></div>


<span class="k">def</span> <span class="nf">_spherical_k_means_plusplus</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">n_local_trials</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computational component for initialization of n_clusters by</span>
<span class="sd">    k-means++. Prior validation of data is assumed.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The data to pick seeds for.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of seeds to choose.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in `X`.</span>

<span class="sd">    random_state : RandomState instance</span>
<span class="sd">        The generator used to initialize the centers.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    n_local_trials : int, default=None</span>
<span class="sd">        The number of seeding trials for each center (except the first),</span>
<span class="sd">        of which the one reducing inertia the most is greedily chosen.</span>
<span class="sd">        Set to None to make the number of trials depend logarithmically</span>
<span class="sd">        on the number of seeds (2+log(k)); this is the default.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers for k-means.</span>

<span class="sd">    indices : ndarray of shape (n_clusters,)</span>
<span class="sd">        The index location of the chosen centers in the data array X. For a</span>
<span class="sd">        given index and center, X[index] = center.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">centers</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">n_features</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Set the number of local seeding trials if none is given</span>
    <span class="k">if</span> <span class="n">n_local_trials</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># This is what Arthur/Vassilvitskii tried, but did not report</span>
        <span class="c1"># specific results for other than mentioning in the conclusion</span>
        <span class="c1"># that it helped.</span>
        <span class="n">n_local_trials</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">+</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">))</span>

    <span class="c1"># Pick first center randomly and track index of point</span>
    <span class="n">center_id</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">sample_weight</span> <span class="o">/</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="n">center_id</span><span class="p">]]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">center_id</span><span class="p">]</span>
    <span class="n">indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">center_id</span>

    <span class="c1"># Initialize list of closest distances and calculate current potential</span>
    <span class="n">closest_dist_sq</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">centers</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">current_pot</span> <span class="o">=</span> <span class="n">closest_dist_sq</span> <span class="o">@</span> <span class="n">sample_weight</span>

    <span class="c1"># Pick the remaining n_clusters-1 points</span>
    <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">):</span>
        <span class="c1"># Choose center candidates by sampling with probability proportional</span>
        <span class="c1"># to the squared distance to the closest existing center</span>
        <span class="n">rand_vals</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n_local_trials</span><span class="p">)</span> <span class="o">*</span> <span class="n">current_pot</span>
        <span class="n">candidate_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span>
            <span class="n">stable_cumsum</span><span class="p">(</span><span class="n">sample_weight</span> <span class="o">*</span> <span class="n">closest_dist_sq</span><span class="p">),</span> <span class="n">rand_vals</span>
        <span class="p">)</span>
        <span class="c1"># XXX: numerical imprecision can result in a candidate_id out of range</span>
        <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">candidate_ids</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closest_dist_sq</span><span class="o">.</span><span class="n">size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">candidate_ids</span><span class="p">)</span>

        <span class="c1"># Compute distances to center candidates</span>
        <span class="n">distance_to_candidates</span> <span class="o">=</span> <span class="n">cosine_distances</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">candidate_ids</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>

        <span class="c1"># update closest distances squared and potential for each candidate</span>
        <span class="n">np</span><span class="o">.</span><span class="n">minimum</span><span class="p">(</span><span class="n">closest_dist_sq</span><span class="p">,</span> <span class="n">distance_to_candidates</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">distance_to_candidates</span><span class="p">)</span>
        <span class="n">candidates_pot</span> <span class="o">=</span> <span class="n">distance_to_candidates</span> <span class="o">@</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Decide which candidate is the best</span>
        <span class="n">best_candidate</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">candidates_pot</span><span class="p">)</span>
        <span class="n">current_pot</span> <span class="o">=</span> <span class="n">candidates_pot</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">closest_dist_sq</span> <span class="o">=</span> <span class="n">distance_to_candidates</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">best_candidate</span> <span class="o">=</span> <span class="n">candidate_ids</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>

        <span class="c1"># Permanently add best center candidate found in local tries</span>
        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">centers</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[[</span><span class="n">best_candidate</span><span class="p">]]</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">centers</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">best_candidate</span><span class="p">]</span>
        <span class="n">indices</span><span class="p">[</span><span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_candidate</span>

    <span class="k">return</span> <span class="n">centers</span><span class="p">,</span> <span class="n">indices</span>


<span class="c1">###############################################################################</span>
<span class="c1"># K-means batch estimation by EM (expectation maximization)</span>


<span class="k">def</span> <span class="nf">_tolerance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">tol</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return a tolerance which is dependent on the dataset.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">tol</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">mean_variance_axis</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">variances</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">variances</span><span class="p">)</span> <span class="o">*</span> <span class="n">tol</span>


<span class="nd">@validate_params</span><span class="p">(</span>
    <span class="p">{</span>
        <span class="s2">&quot;X&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse matrix&quot;</span><span class="p">],</span>
        <span class="s2">&quot;sample_weight&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;array-like&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;return_n_iter&quot;</span><span class="p">:</span> <span class="p">[</span><span class="nb">bool</span><span class="p">],</span>
    <span class="p">},</span>
    <span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<div class="viewcode-block" id="spherical_k_means"><a class="viewcode-back" href="../../../autoapi/spsklearn/cluster/index.html#spsklearn.cluster._spherical_k_means.spherical_k_means">[docs]</a><span class="p">)</span>
<span class="k">def</span> <span class="nf">spherical_k_means</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">n_clusters</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">init</span><span class="o">=</span><span class="s2">&quot;spherical-k-means++&quot;</span><span class="p">,</span>
    <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;lloyd&quot;</span><span class="p">,</span>
    <span class="n">return_n_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform K-means clustering algorithm.</span>

<span class="sd">    Read more in the :ref:`User Guide &lt;k_means&gt;`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The observations to cluster. It must be noted that the data</span>
<span class="sd">        will be converted to C ordering, which will cause a memory copy</span>
<span class="sd">        if the given data is not C-contiguous.</span>

<span class="sd">    n_clusters : int</span>
<span class="sd">        The number of clusters to form as well as the number of</span>
<span class="sd">        centroids to generate.</span>

<span class="sd">    sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">        The weights for each observation in `X`. If `None`, all observations</span>
<span class="sd">        are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">        initialization if `init` is a callable or a user provided array.</span>

<span class="sd">    init : {&#39;spherical-k-means++&#39;, &#39;random&#39;}, callable or array-like of shape \</span>
<span class="sd">            (n_clusters, n_features), default=&#39;spherical-k-means++&#39;</span>
<span class="sd">        Method for initialization:</span>

<span class="sd">        - `&#39;spherical-k-means++&#39;` : selects initial cluster centers for k-mean</span>
<span class="sd">          clustering in a smart way to speed up convergence. See section</span>
<span class="sd">          Notes in k_init for more details.</span>
<span class="sd">        - `&#39;random&#39;`: choose `n_clusters` observations (rows) at random from data</span>
<span class="sd">          for the initial centroids.</span>
<span class="sd">        - If an array is passed, it should be of shape `(n_clusters, n_features)`</span>
<span class="sd">          and gives the initial centers.</span>
<span class="sd">        - If a callable is passed, it should take arguments `X`, `n_clusters` and a</span>
<span class="sd">          random state and return an initialization.</span>

<span class="sd">    n_init : &#39;auto&#39; or int, default=&quot;auto&quot;</span>
<span class="sd">        Number of time the k-means algorithm will be run with different</span>
<span class="sd">        centroid seeds. The final results will be the best output of</span>
<span class="sd">        n_init consecutive runs in terms of inertia.</span>

<span class="sd">        When `n_init=&#39;auto&#39;`, the number of runs depends on the value of init:</span>
<span class="sd">        10 if using `init=&#39;random&#39;` or `init` is a callable;</span>
<span class="sd">        1 if using `init=&#39;spherical-k-means++&#39;` or `init` is an array-like.</span>

<span class="sd">        .. versionadded:: 1.2</span>
<span class="sd">           Added &#39;auto&#39; option for `n_init`.</span>

<span class="sd">        .. versionchanged:: 1.4</span>
<span class="sd">           Default value for `n_init` changed to `&#39;auto&#39;`.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm to run.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Use</span>
<span class="sd">        an int to make the randomness deterministic.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    copy_x : bool, default=True</span>
<span class="sd">        When pre-computing distances it is more numerically accurate to center</span>
<span class="sd">        the data first. If `copy_x` is True (default), then the original data is</span>
<span class="sd">        not modified. If False, the original data is modified, and put back</span>
<span class="sd">        before the function returns, but small numerical differences may be</span>
<span class="sd">        introduced by subtracting and then adding the data mean. Note that if</span>
<span class="sd">        the original data is not C-contiguous, a copy will be made even if</span>
<span class="sd">        `copy_x` is False. If the original data is sparse, but not in CSR format,</span>
<span class="sd">        a copy will be made even if `copy_x` is False.</span>

<span class="sd">    algorithm : {&quot;lloyd&quot;}, default=&quot;lloyd&quot;</span>
<span class="sd">        K-means algorithm to use. The classical EM-style algorithm is `&quot;lloyd&quot;`.</span>
<span class="sd">        The `&quot;elkan&quot;` variation can be more efficient on some datasets with</span>
<span class="sd">        well-defined clusters, by using the triangle inequality. However it&#39;s</span>
<span class="sd">        more memory intensive due to the allocation of an extra array of shape</span>
<span class="sd">        `(n_samples, n_clusters)`.</span>

<span class="sd">    return_n_iter : bool, default=False</span>
<span class="sd">        Whether or not to return the number of iterations.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    centroid : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Centroids found at the last iteration of k-means.</span>

<span class="sd">    label : ndarray of shape (n_samples,)</span>
<span class="sd">        The `label[i]` is the code or index of the centroid the</span>
<span class="sd">        i&#39;th observation is closest to.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        The final value of the inertia criterion (sum of squared distances to</span>
<span class="sd">        the closest centroid for all observations in the training set).</span>

<span class="sd">    best_n_iter : int</span>
<span class="sd">        Number of iterations corresponding to the best results.</span>
<span class="sd">        Returned only if `return_n_iter` is set to True.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; import numpy as np</span>
<span class="sd">    &gt;&gt;&gt; from sklearn.cluster import k_means</span>
<span class="sd">    &gt;&gt;&gt; X = np.array([[1, 2], [1, 4], [1, 0],</span>
<span class="sd">    ...               [10, 2], [10, 4], [10, 0]])</span>
<span class="sd">    &gt;&gt;&gt; centroid, label, inertia = k_means(</span>
<span class="sd">    ...     X, n_clusters=2, n_init=&quot;auto&quot;, random_state=0</span>
<span class="sd">    ... )</span>
<span class="sd">    &gt;&gt;&gt; centroid</span>
<span class="sd">    array([[10.,  2.],</span>
<span class="sd">           [ 1.,  2.]])</span>
<span class="sd">    &gt;&gt;&gt; label</span>
<span class="sd">    array([1, 1, 1, 0, 0, 0], dtype=int32)</span>
<span class="sd">    &gt;&gt;&gt; inertia</span>
<span class="sd">    16.0</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">est</span> <span class="o">=</span> <span class="n">SphericalKMeans</span><span class="p">(</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="n">n_init</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="n">copy_x</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="n">algorithm</span><span class="p">,</span>
    <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_n_iter</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">est</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">inertia_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">n_iter_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">est</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">labels_</span><span class="p">,</span> <span class="n">est</span><span class="o">.</span><span class="n">inertia_</span></div>


<span class="k">def</span> <span class="nf">_spherical_k_means_single_lloyd</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>
    <span class="n">sample_weight</span><span class="p">,</span>
    <span class="n">centers_init</span><span class="p">,</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
    <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A single run of spherical k-means lloyd, assumes preparation completed prior.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The observations to cluster. If sparse matrix, must be in CSR format.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in X.</span>

<span class="sd">    centers_init : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The initial centers.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm to run.</span>

<span class="sd">    verbose : bool, default=False</span>
<span class="sd">        Verbosity mode</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>
<span class="sd">        It&#39;s not advised to set `tol=0` since convergence might never be</span>
<span class="sd">        declared due to rounding errors. Use a very small number instead.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation. Parallelism is</span>
<span class="sd">        sample-wise on the main cython loop which assigns each sample to its</span>
<span class="sd">        closest center.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    label : ndarray of shape (n_samples,)</span>
<span class="sd">        label[i] is the code or index of the centroid the</span>
<span class="sd">        i&#39;th observation is closest to.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        The final value of the inertia criterion (sum of squared distances to</span>
<span class="sd">        the closest centroid for all observations in the training set).</span>

<span class="sd">    centroid : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Centroids found at the last iteration of k-means.</span>

<span class="sd">    n_iter : int</span>
<span class="sd">        Number of iterations run.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">centers_init</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Buffers to avoid new allocations at each iteration.</span>
    <span class="n">centers</span> <span class="o">=</span> <span class="n">centers_init</span>
    <span class="n">centers_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">centers</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">labels_old</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">weight_in_clusters</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">center_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">lloyd_iter</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_sparse</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_sparse</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lloyd_iter</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_dense</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_dense</span>

    <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Threadpoolctl context to limit the number of threads in second level of</span>
    <span class="c1"># nested parallelism (i.e. BLAS) to avoid oversubscription.</span>
    <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">):</span>
            <span class="n">lloyd_iter</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">centers_new</span><span class="p">,</span>
                <span class="n">weight_in_clusters</span><span class="p">,</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">center_shift</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">, inertia </span><span class="si">{</span><span class="n">inertia</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

            <span class="n">centers</span><span class="p">,</span> <span class="n">centers_new</span> <span class="o">=</span> <span class="n">centers_new</span><span class="p">,</span> <span class="n">centers</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">labels_old</span><span class="p">):</span>
                <span class="c1"># First check the labels for strict convergence.</span>
                <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: strict convergence.&quot;</span><span class="p">)</span>
                <span class="n">strict_convergence</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="k">break</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># No strict convergence, check for tol based convergence.</span>
                <span class="n">center_shift_tot</span> <span class="o">=</span> <span class="p">(</span><span class="n">center_shift</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">center_shift_tot</span> <span class="o">&lt;=</span> <span class="n">tol</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
                        <span class="nb">print</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;Converged at iteration </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: center shift &quot;</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">center_shift_tot</span><span class="si">}</span><span class="s2"> within tolerance </span><span class="si">{</span><span class="n">tol</span><span class="si">}</span><span class="s2">.&quot;</span>
                        <span class="p">)</span>
                    <span class="k">break</span>

            <span class="n">labels_old</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">labels</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">strict_convergence</span><span class="p">:</span>
            <span class="c1"># rerun E-step so that predicted labels match cluster centers</span>
            <span class="n">lloyd_iter</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">centers</span><span class="p">,</span>
                <span class="n">weight_in_clusters</span><span class="p">,</span>
                <span class="n">labels</span><span class="p">,</span>
                <span class="n">center_shift</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="p">,</span>
                <span class="n">update_centers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>


<span class="k">def</span> <span class="nf">_labels_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inertia</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;E step of the K-means EM algorithm.</span>

<span class="sd">    Compute the labels and the inertia of the given samples and centers.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">        The input samples to assign to the labels. If sparse matrix, must</span>
<span class="sd">        be in CSR format.</span>

<span class="sd">    sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">        The weights for each observation in X.</span>

<span class="sd">    x_squared_norms : ndarray of shape (n_samples,)</span>
<span class="sd">        Precomputed squared euclidean norm of each data point, to speed up</span>
<span class="sd">        computations.</span>

<span class="sd">    centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        The cluster centers.</span>

<span class="sd">    n_threads : int, default=1</span>
<span class="sd">        The number of OpenMP threads to use for the computation. Parallelism is</span>
<span class="sd">        sample-wise on the main cython loop which assigns each sample to its</span>
<span class="sd">        closest center.</span>

<span class="sd">    return_inertia : bool, default=True</span>
<span class="sd">        Whether to compute and return the inertia.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    labels : ndarray of shape (n_samples,)</span>
<span class="sd">        The resulting assignment.</span>

<span class="sd">    inertia : float</span>
<span class="sd">        Sum of squared distances of samples to their closest cluster center.</span>
<span class="sd">        Inertia is only returned if return_inertia is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_clusters</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">center_shift</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_clusters</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">centers</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
        <span class="n">_labels</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_sparse</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_sparse</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">_labels</span> <span class="o">=</span> <span class="n">lloyd_iter_chunked_dense</span>
        <span class="n">_inertia</span> <span class="o">=</span> <span class="n">_inertia_dense</span>

    <span class="n">_labels</span><span class="p">(</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">centers</span><span class="p">,</span>
        <span class="n">centers_new</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_in_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
        <span class="n">center_shift</span><span class="o">=</span><span class="n">center_shift</span><span class="p">,</span>
        <span class="n">n_threads</span><span class="o">=</span><span class="n">n_threads</span><span class="p">,</span>
        <span class="n">update_centers</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">return_inertia</span><span class="p">:</span>
        <span class="n">inertia</span> <span class="o">=</span> <span class="n">_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span>

    <span class="k">return</span> <span class="n">labels</span>


<span class="k">def</span> <span class="nf">_labels_inertia_threadpool_limit</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">return_inertia</span><span class="o">=</span><span class="kc">True</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Same as _labels_inertia but in a threadpool_limits context.&quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">threadpool_limits</span><span class="p">(</span><span class="n">limits</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">user_api</span><span class="o">=</span><span class="s2">&quot;blas&quot;</span><span class="p">):</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_labels_inertia</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sample_weight</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_threads</span><span class="p">,</span> <span class="n">return_inertia</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="SphericalKMeans"><a class="viewcode-back" href="../../../autoapi/spsklearn/cluster/index.html#spsklearn.cluster._spherical_k_means.SphericalKMeans">[docs]</a><span class="k">class</span> <span class="nc">SphericalKMeans</span><span class="p">(</span><span class="n">_BaseKMeans</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Spherical K-Means clustering.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n_clusters : int, default=8</span>
<span class="sd">        The number of clusters to form as well as the number of</span>
<span class="sd">        centroids to generate.</span>

<span class="sd">    init : {&#39;spherical-k-means++&#39;, &#39;random&#39;}, callable or array-like of shape \</span>
<span class="sd">            (n_clusters, n_features), default=&#39;spherical-k-means++&#39;</span>
<span class="sd">        Method for initialization:</span>

<span class="sd">        * &#39;spherical-k-means++&#39; : selects initial cluster centroids using sampling \</span>
<span class="sd">            based on an empirical probability distribution of the points&#39; \</span>
<span class="sd">            contribution to the overall inertia. This technique speeds up \</span>
<span class="sd">            convergence. The algorithm implemented is &quot;greedy spherical-k-means++&quot;. It \</span>
<span class="sd">            differs from the vanilla spherical-k-means++ by making several trials at \</span>
<span class="sd">            each sampling step and choosing the best centroid among them.</span>

<span class="sd">        * &#39;random&#39;: choose `n_clusters` observations (rows) at random from \</span>
<span class="sd">        data for the initial centroids.</span>

<span class="sd">        * If an array is passed, it should be of shape (n_clusters, n_features)\</span>
<span class="sd">        and gives the initial centers.</span>

<span class="sd">        * If a callable is passed, it should take arguments X, n_clusters and a\</span>
<span class="sd">        random state and return an initialization.</span>

<span class="sd">        For an example of how to use the different `init` strategy, see the example</span>
<span class="sd">        entitled :ref:`sphx_glr_auto_examples_cluster_plot_kmeans_digits.py`.</span>

<span class="sd">    n_init : &#39;auto&#39; or int, default=&#39;auto&#39;</span>
<span class="sd">        Number of times the k-means algorithm is run with different centroid</span>
<span class="sd">        seeds. The final results is the best output of `n_init` consecutive runs</span>
<span class="sd">        in terms of inertia. Several runs are recommended for sparse</span>
<span class="sd">        high-dimensional problems (see :ref:`kmeans_sparse_high_dim`).</span>

<span class="sd">        When `n_init=&#39;auto&#39;`, the number of runs depends on the value of init:</span>
<span class="sd">        10 if using `init=&#39;random&#39;` or `init` is a callable;</span>
<span class="sd">        1 if using `init=&#39;spherical-k-means++&#39;` or `init` is an array-like.</span>

<span class="sd">    max_iter : int, default=300</span>
<span class="sd">        Maximum number of iterations of the k-means algorithm for a</span>
<span class="sd">        single run.</span>

<span class="sd">    tol : float, default=1e-4</span>
<span class="sd">        Relative tolerance with regards to Frobenius norm of the difference</span>
<span class="sd">        in the cluster centers of two consecutive iterations to declare</span>
<span class="sd">        convergence.</span>

<span class="sd">    verbose : int, default=0</span>
<span class="sd">        Verbosity mode.</span>

<span class="sd">    random_state : int, RandomState instance or None, default=None</span>
<span class="sd">        Determines random number generation for centroid initialization. Use</span>
<span class="sd">        an int to make the randomness deterministic.</span>
<span class="sd">        See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">    copy_x : bool, default=True</span>
<span class="sd">        When pre-computing distances it is more numerically accurate to center</span>
<span class="sd">        the data first. If copy_x is True (default), then the original data is</span>
<span class="sd">        not modified. If False, the original data is modified, and put back</span>
<span class="sd">        before the function returns, but small numerical differences may be</span>
<span class="sd">        introduced by subtracting and then adding the data mean. Note that if</span>
<span class="sd">        the original data is not C-contiguous, a copy will be made even if</span>
<span class="sd">        copy_x is False. If the original data is sparse, but not in CSR format,</span>
<span class="sd">        a copy will be made even if copy_x is False.</span>

<span class="sd">    algorithm : {&quot;lloyd&quot;}, default=&quot;lloyd&quot;</span>
<span class="sd">        spherical K-means algorithm to use. The classical EM-style algorithm is `&quot;lloyd&quot;`.</span>
<span class="sd">        The `&quot;elkan&quot;` variation can be more efficient on some datasets with</span>
<span class="sd">        well-defined clusters, by using the triangle inequality. However it&#39;s</span>
<span class="sd">        more memory intensive due to the allocation of an extra array of shape</span>
<span class="sd">        `(n_samples, n_clusters)`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    cluster_centers_ : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">        Coordinates of cluster centers. If the algorithm stops before fully</span>
<span class="sd">        converging (see ``tol`` and ``max_iter``), these will not be</span>
<span class="sd">        consistent with ``labels_``.</span>

<span class="sd">    labels_ : ndarray of shape (n_samples,)</span>
<span class="sd">        Labels of each point</span>

<span class="sd">    inertia_ : float</span>
<span class="sd">        Sum of squared distances of samples to their closest cluster center,</span>
<span class="sd">        weighted by the sample weights if provided.</span>

<span class="sd">    n_iter_ : int</span>
<span class="sd">        Number of iterations run.</span>

<span class="sd">    n_features_in_ : int</span>
<span class="sd">        Number of features seen during :term:`fit`.</span>

<span class="sd">    feature_names_in_ : ndarray of shape (`n_features_in_`,)</span>
<span class="sd">        Names of features seen during :term:`fit`. Defined only when `X`</span>
<span class="sd">        has feature names that are all strings.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    The spherical k-means problem is solved using either Lloyd&#39;s or Elkan&#39;s algorithm.</span>

<span class="sd">    The average complexity is given by O(k n T), where n is the number of</span>
<span class="sd">    samples and T is the number of iteration.</span>

<span class="sd">    The worst case complexity is given by O(n^(k+2/p)) with</span>
<span class="sd">    n = n_samples, p = n_features.</span>
<span class="sd">    Refer to :doi:`&quot;How slow is the k-means method?&quot; D. Arthur and S. Vassilvitskii -</span>
<span class="sd">    SoCG2006.&lt;10.1145/1137856.1137880&gt;` for more details.</span>

<span class="sd">    In practice, the k-means algorithm is very fast (one of the fastest</span>
<span class="sd">    clustering algorithms available), but it falls in local minima. That&#39;s why</span>
<span class="sd">    it can be useful to restart it several times.</span>

<span class="sd">    If the algorithm stops before fully converging (because of ``tol`` or</span>
<span class="sd">    ``max_iter``), ``labels_`` and ``cluster_centers_`` will not be consistent,</span>
<span class="sd">    i.e. the ``cluster_centers_`` will not be the means of the points in each</span>
<span class="sd">    cluster. Also, the estimator will reassign ``labels_`` after the last</span>
<span class="sd">    iteration to make ``labels_`` consistent with ``predict`` on the training</span>
<span class="sd">    set.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_parameter_constraints</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="o">**</span><span class="n">_BaseKMeans</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
        <span class="s2">&quot;copy_x&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;boolean&quot;</span><span class="p">],</span>
        <span class="s2">&quot;algorithm&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;lloyd&quot;</span><span class="p">})],</span>
    <span class="p">}</span>
    <span class="n">_parameter_constraints</span><span class="o">.</span><span class="n">update</span><span class="p">({</span>
        <span class="s2">&quot;init&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">StrOptions</span><span class="p">({</span><span class="s2">&quot;spherical-k-means++&quot;</span><span class="p">,</span> <span class="s2">&quot;random&quot;</span><span class="p">}),</span> <span class="n">callable</span><span class="p">,</span> <span class="s2">&quot;array-like&quot;</span><span class="p">],</span>
    <span class="p">})</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_clusters</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="o">*</span><span class="p">,</span>
        <span class="n">init</span><span class="o">=</span><span class="s2">&quot;spherical-k-means++&quot;</span><span class="p">,</span>
        <span class="n">n_init</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
        <span class="n">tol</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">copy_x</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;lloyd&quot;</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
            <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
            <span class="n">n_init</span><span class="o">=</span><span class="n">n_init</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">copy_x</span> <span class="o">=</span> <span class="n">copy_x</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">=</span> <span class="n">algorithm</span>

    <span class="k">def</span> <span class="nf">_check_params_vs_input</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">default_n_init</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">algorithm</span> <span class="o">==</span> <span class="s2">&quot;lloyd&quot;</span><span class="p">,</span> <span class="s2">&quot;Only algorithm=&#39;lloyd&#39; is supported now.&quot;</span>

    <span class="k">def</span> <span class="nf">_warn_mkl_vcomp</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_active_threads</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Warn when vcomp and mkl are both present&quot;&quot;&quot;</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;KMeans is known to have a memory leak on Windows &quot;</span>
            <span class="s2">&quot;with MKL, when there are less chunks than available &quot;</span>
            <span class="s2">&quot;threads. You can avoid it by setting the environment&quot;</span>
            <span class="sa">f</span><span class="s2">&quot; variable OMP_NUM_THREADS=</span><span class="si">{</span><span class="n">n_active_threads</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_init_centroids</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">,</span>
        <span class="n">init</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">,</span>
        <span class="n">sample_weight</span><span class="p">,</span>
        <span class="n">init_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_centroids</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute the initial centroids.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {ndarray, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            The input samples.</span>

<span class="sd">        init : {&#39;spherical-k-means++&#39;, &#39;random&#39;}, callable or ndarray of shape \</span>
<span class="sd">                (n_clusters, n_features)</span>
<span class="sd">            Method for initialization.</span>

<span class="sd">        random_state : RandomState instance</span>
<span class="sd">            Determines random number generation for centroid initialization.</span>
<span class="sd">            See :term:`Glossary &lt;random_state&gt;`.</span>

<span class="sd">        sample_weight : ndarray of shape (n_samples,)</span>
<span class="sd">            The weights for each observation in X. `sample_weight` is not used</span>
<span class="sd">            during initialization if `init` is a callable or a user provided</span>
<span class="sd">            array.</span>

<span class="sd">        init_size : int, default=None</span>
<span class="sd">            Number of samples to randomly sample for speeding up the</span>
<span class="sd">            initialization (sometimes at the expense of accuracy).</span>

<span class="sd">        n_centroids : int, default=None</span>
<span class="sd">            Number of centroids to initialize.</span>
<span class="sd">            If left to &#39;None&#39; the number of centroids will be equal to</span>
<span class="sd">            number of clusters to form (self.n_clusters).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        centers : ndarray of shape (n_clusters, n_features)</span>
<span class="sd">            Initial centroids of clusters.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">n_clusters</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span> <span class="k">if</span> <span class="n">n_centroids</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">n_centroids</span>

        <span class="k">if</span> <span class="n">init_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">init_size</span> <span class="o">&lt;</span> <span class="n">n_samples</span><span class="p">:</span>
            <span class="n">init_indices</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">init_size</span><span class="p">)</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>
            <span class="n">x_squared_norms</span> <span class="o">=</span> <span class="n">x_squared_norms</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>
            <span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">[</span><span class="n">init_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;spherical-k-means++&quot;</span><span class="p">:</span>
            <span class="n">centers</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">_spherical_k_means_plusplus</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">n_clusters</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="n">init</span> <span class="o">==</span> <span class="s2">&quot;random&quot;</span><span class="p">:</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                <span class="n">n_samples</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
                <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">p</span><span class="o">=</span><span class="n">sample_weight</span> <span class="o">/</span> <span class="n">sample_weight</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span>
            <span class="p">)</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">seeds</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">init</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">init</span>
        <span class="k">elif</span> <span class="n">callable</span><span class="p">(</span><span class="n">init</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">init</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_clusters</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">centers</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">centers</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sp</span><span class="o">.</span><span class="n">issparse</span><span class="p">(</span><span class="n">centers</span><span class="p">):</span>
            <span class="n">centers</span> <span class="o">=</span> <span class="n">centers</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">centers</span>

    <span class="nd">@_fit_context</span><span class="p">(</span><span class="n">prefer_skip_nested_validation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<div class="viewcode-block" id="SphericalKMeans.fit"><a class="viewcode-back" href="../../../autoapi/spsklearn/cluster/_spherical_k_means/index.html#spsklearn.cluster._spherical_k_means.SphericalKMeans.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute spherical k-means clustering.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X : {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Training instances to cluster. It must be noted that the data</span>
<span class="sd">            will be converted to C ordering, which will cause a memory</span>
<span class="sd">            copy if the given data is not C-contiguous.</span>
<span class="sd">            If a sparse matrix is passed, a copy will be made if it&#39;s not in</span>
<span class="sd">            CSR format.</span>

<span class="sd">        y : Ignored</span>
<span class="sd">            Not used, present here for API consistency by convention.</span>

<span class="sd">        sample_weight : array-like of shape (n_samples,), default=None</span>
<span class="sd">            The weights for each observation in X. If None, all observations</span>
<span class="sd">            are assigned equal weight. `sample_weight` is not used during</span>
<span class="sd">            initialization if `init` is a callable or a user provided array.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self : object</span>
<span class="sd">            Fitted estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_validate_data</span><span class="p">(</span>
            <span class="n">X</span><span class="p">,</span>
            <span class="n">accept_sparse</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">],</span>
            <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">,</span>
            <span class="n">copy</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">copy_x</span><span class="p">,</span>
            <span class="n">accept_large_sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">check_spherical_array</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">spherical_axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_check_params_vs_input</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="n">random_state</span> <span class="o">=</span> <span class="n">check_random_state</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">random_state</span><span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">_check_sample_weight</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span> <span class="o">=</span> <span class="n">_openmp_effective_n_threads</span><span class="p">()</span>

        <span class="c1"># Validate init array</span>
        <span class="n">init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init</span>
        <span class="n">init_is_array_like</span> <span class="o">=</span> <span class="n">_is_arraylike_not_scalar</span><span class="p">(</span><span class="n">init</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">init_is_array_like</span><span class="p">:</span>
            <span class="n">init</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">init</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="s2">&quot;C&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_validate_center_shape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">init</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span> <span class="o">==</span> <span class="s2">&quot;lloyd&quot;</span><span class="p">:</span>
            <span class="n">kmeans_single</span> <span class="o">=</span> <span class="n">_spherical_k_means_single_lloyd</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="s2">&quot;&#39;algorithm=</span><span class="si">{}</span><span class="s2">&#39; is not supported.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_algorithm</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">best_inertia</span><span class="p">,</span> <span class="n">best_labels</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_init</span><span class="p">):</span>
            <span class="c1"># TODO: fix bugs here</span>
            <span class="c1"># Initialize centers</span>
            <span class="n">centers_init</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_centroids</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">init</span><span class="o">=</span><span class="n">init</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Initialization complete&quot;</span><span class="p">)</span>

            <span class="c1"># run a k-means once</span>
            <span class="n">labels</span><span class="p">,</span> <span class="n">inertia</span><span class="p">,</span> <span class="n">centers</span><span class="p">,</span> <span class="n">n_iter_</span> <span class="o">=</span> <span class="n">kmeans_single</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">sample_weight</span><span class="p">,</span>
                <span class="n">centers_init</span><span class="p">,</span>
                <span class="n">max_iter</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span><span class="p">,</span>
                <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
                <span class="n">tol</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_tol</span><span class="p">,</span>
                <span class="n">n_threads</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_threads</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># determine if these results are the best so far</span>
            <span class="c1"># we chose a new run if it has a better inertia and the clustering is</span>
            <span class="c1"># different from the best so far (it&#39;s possible that the inertia is</span>
            <span class="c1"># slightly better even if the clustering is the same with potentially</span>
            <span class="c1"># permuted labels, due to rounding errors)</span>
            <span class="k">if</span> <span class="n">best_inertia</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">inertia</span> <span class="o">&lt;</span> <span class="n">best_inertia</span>
                <span class="ow">and</span> <span class="ow">not</span> <span class="n">_is_same_clustering</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">best_labels</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="n">best_labels</span> <span class="o">=</span> <span class="n">labels</span>
                <span class="n">best_centers</span> <span class="o">=</span> <span class="n">centers</span>
                <span class="n">best_inertia</span> <span class="o">=</span> <span class="n">inertia</span>
                <span class="n">best_n_iter</span> <span class="o">=</span> <span class="n">n_iter_</span>

        <span class="n">distinct_clusters</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">best_labels</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">distinct_clusters</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="s2">&quot;Number of distinct clusters (</span><span class="si">{}</span><span class="s2">) found smaller than &quot;</span>
                <span class="s2">&quot;n_clusters (</span><span class="si">{}</span><span class="s2">). Possibly due to duplicate points &quot;</span>
                <span class="s2">&quot;in X.&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">distinct_clusters</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">),</span>
                <span class="n">ConvergenceWarning</span><span class="p">,</span>
                <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span> <span class="o">=</span> <span class="n">best_centers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_features_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">labels_</span> <span class="o">=</span> <span class="n">best_labels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inertia_</span> <span class="o">=</span> <span class="n">best_inertia</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_iter_</span> <span class="o">=</span> <span class="n">best_n_iter</span>
        <span class="k">return</span> <span class="bp">self</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright Jiaqi Li

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>